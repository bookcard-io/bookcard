# Copyright (C) 2025 knguyen and others
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.

"""Add openlibrary dump tables.

Revision ID: 34c7ece3865c
Revises: eef7233e099c
Create Date: 2025-11-20 07:28:18.079983

"""

from collections.abc import Sequence

import sqlalchemy as sa
import sqlmodel
from alembic import op

from bookcard.models.openlibrary import JSONBType

# revision identifiers, used by Alembic.
revision: str = "34c7ece3865c"
down_revision: str | Sequence[str] | None = "eef7233e099c"
branch_labels: str | Sequence[str] | None = None
depends_on: str | Sequence[str] | None = None


def upgrade() -> None:
    """Upgrade schema."""
    # Detect database dialect
    connection = op.get_bind()
    is_postgresql = connection.dialect.name == "postgresql"

    # Enable pg_trgm extension for trigram text search indexes (PostgreSQL only)
    if is_postgresql:
        op.execute(sa.text("CREATE EXTENSION IF NOT EXISTS pg_trgm"))

    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "openlibrary_author_works",
        sa.Column("author_key", sa.Text(), nullable=False),
        sa.Column("work_key", sa.Text(), nullable=False),
        sa.PrimaryKeyConstraint("author_key", "work_key"),
    )
    op.create_index(
        "cuix_openlibrary_authorworks_authorkey_workkey",
        "openlibrary_author_works",
        ["author_key", "work_key"],
        unique=True,
    )
    op.create_index(
        "ix_openlibrary_authorworks_authorkey",
        "openlibrary_author_works",
        ["author_key"],
        unique=False,
    )
    op.create_index(
        "ix_openlibrary_authorworks_workkey",
        "openlibrary_author_works",
        ["work_key"],
        unique=False,
    )
    # Cluster table on composite primary key index for better performance
    if is_postgresql:
        op.execute(
            sa.text(
                "ALTER TABLE openlibrary_author_works CLUSTER ON "
                "cuix_openlibrary_authorworks_authorkey_workkey"
            )
        )
    op.create_table(
        "openlibrary_authors",
        sa.Column("type", sa.Text(), nullable=True),
        sa.Column("key", sa.Text(), nullable=False),
        sa.Column("revision", sa.Integer(), nullable=True),
        sa.Column("last_modified", sa.Date(), nullable=True),
        sa.Column("data", JSONBType(), nullable=True),
        sa.PrimaryKeyConstraint("key"),
    )
    op.create_index(
        "cuix_openlibrary_authors_key", "openlibrary_authors", ["key"], unique=True
    )
    if is_postgresql:
        # Cluster table on primary key index for better performance
        op.execute(
            sa.text(
                "ALTER TABLE openlibrary_authors CLUSTER ON cuix_openlibrary_authors_key"
            )
        )
        # Create GIN index on JSONB data for efficient JSON queries
        op.execute(
            sa.text(
                "CREATE INDEX ix_openlibrary_authors_data ON openlibrary_authors "
                "USING gin (data jsonb_path_ops)"
            )
        )
        # Create GIN trigram index on name field for text search
        op.execute(
            sa.text(
                "CREATE INDEX ix_openlibrary_authors_name ON openlibrary_authors "
                "USING gin ((data->>'name') gin_trgm_ops)"
            )
        )
    op.create_table(
        "openlibrary_edition_isbns",
        sa.Column("edition_key", sa.Text(), nullable=False),
        sa.Column("isbn", sa.Text(), nullable=False),
        sa.PrimaryKeyConstraint("edition_key", "isbn"),
    )
    op.create_index(
        "cuix_openlibrary_editionisbns_editionkey_isbn",
        "openlibrary_edition_isbns",
        ["edition_key", "isbn"],
        unique=True,
    )
    op.create_index(
        "ix_openlibrary_editionisbns_editionkey",
        "openlibrary_edition_isbns",
        ["edition_key"],
        unique=False,
    )
    op.create_index(
        "ix_openlibrary_editionisbns_isbn",
        "openlibrary_edition_isbns",
        ["isbn"],
        unique=False,
    )
    if is_postgresql:
        # Cluster table on composite primary key index for better performance
        op.execute(
            sa.text(
                "ALTER TABLE openlibrary_edition_isbns CLUSTER ON "
                "cuix_openlibrary_editionisbns_editionkey_isbn"
            )
        )
    op.create_table(
        "openlibrary_editions",
        sa.Column("type", sa.Text(), nullable=True),
        sa.Column("key", sa.Text(), nullable=False),
        sa.Column("revision", sa.Integer(), nullable=True),
        sa.Column("last_modified", sa.Date(), nullable=True),
        sa.Column("data", JSONBType(), nullable=True),
        sa.Column("work_key", sa.Text(), nullable=True),
        sa.PrimaryKeyConstraint("key"),
    )
    op.create_index(
        "cuix_openlibrary_editions_key", "openlibrary_editions", ["key"], unique=True
    )
    op.create_index(
        "ix_openlibrary_editions_workkey",
        "openlibrary_editions",
        ["work_key"],
        unique=False,
    )
    if is_postgresql:
        # Cluster table on primary key index for better performance
        op.execute(
            sa.text(
                "ALTER TABLE openlibrary_editions CLUSTER ON cuix_openlibrary_editions_key"
            )
        )
        # Create GIN index on JSONB data for efficient JSON queries
        op.execute(
            sa.text(
                "CREATE INDEX ix_openlibrary_editions_data ON openlibrary_editions "
                "USING gin (data jsonb_path_ops)"
            )
        )
        # Create GIN trigram indexes on title and subtitle for text search
        op.execute(
            sa.text(
                "CREATE INDEX ix_openlibrary_editions_title ON openlibrary_editions "
                "USING gin ((data->>'title') gin_trgm_ops)"
            )
        )
        op.execute(
            sa.text(
                "CREATE INDEX ix_openlibrary_editions_subtitle ON openlibrary_editions "
                "USING gin ((data->>'subtitle') gin_trgm_ops)"
            )
        )
    op.create_table(
        "openlibrary_works",
        sa.Column("type", sa.Text(), nullable=True),
        sa.Column("key", sa.Text(), nullable=False),
        sa.Column("revision", sa.Integer(), nullable=True),
        sa.Column("last_modified", sa.Date(), nullable=True),
        sa.Column("data", JSONBType(), nullable=True),
        sa.PrimaryKeyConstraint("key"),
    )
    op.create_index(
        "cuix_openlibrary_works_key", "openlibrary_works", ["key"], unique=True
    )
    if is_postgresql:
        # Cluster table on primary key index for better performance
        op.execute(
            sa.text(
                "ALTER TABLE openlibrary_works CLUSTER ON cuix_openlibrary_works_key"
            )
        )
        # Create GIN index on JSONB data for efficient JSON queries
        op.execute(
            sa.text(
                "CREATE INDEX ix_openlibrary_works_data ON openlibrary_works "
                "USING gin (data jsonb_path_ops)"
            )
        )
        # Create GIN trigram indexes on title and subtitle for text search
        op.execute(
            sa.text(
                "CREATE INDEX ix_openlibrary_works_title ON openlibrary_works "
                "USING gin ((data->>'title') gin_trgm_ops)"
            )
        )
        op.execute(
            sa.text(
                "CREATE INDEX ix_openlibrary_works_subtitle ON openlibrary_works "
                "USING gin ((data->>'subtitle') gin_trgm_ops)"
            )
        )
    op.create_table(
        "library_scan_states",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("library_id", sa.Integer(), nullable=False),
        sa.Column("last_scan_at", sa.DateTime(), nullable=True),
        sa.Column("scan_status", sqlmodel.AutoString(length=50), nullable=False),
        sa.Column("books_scanned", sa.Integer(), nullable=False),
        sa.Column("authors_scanned", sa.Integer(), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("updated_at", sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(
            ["library_id"],
            ["libraries.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        op.f("ix_library_scan_states_created_at"),
        "library_scan_states",
        ["created_at"],
        unique=False,
    )
    op.create_index(
        op.f("ix_library_scan_states_last_scan_at"),
        "library_scan_states",
        ["last_scan_at"],
        unique=False,
    )
    op.create_index(
        op.f("ix_library_scan_states_library_id"),
        "library_scan_states",
        ["library_id"],
        unique=True,
    )
    op.create_index(
        op.f("ix_library_scan_states_scan_status"),
        "library_scan_states",
        ["scan_status"],
        unique=False,
    )

    op.drop_index(op.f("ix_shelves_library_id_name_is_public"), table_name="shelves")
    op.drop_index(op.f("ix_shelves_library_id_user_id_is_public"), table_name="shelves")

    # Define the enum type for task_type column
    task_type_enum = sa.Enum(
        "BOOK_UPLOAD",
        "MULTI_BOOK_UPLOAD",
        "BOOK_CONVERT",
        "BOOK_STRIP_DRM",
        "EMAIL_SEND",
        "METADATA_BACKUP",
        "THUMBNAIL_GENERATE",
        "LIBRARY_SCAN",
        "AUTHOR_METADATA_FETCH",
        "OPENLIBRARY_DUMP_DOWNLOAD",
        "OPENLIBRARY_DUMP_INGEST",
        "EPUB_FIX_SINGLE",
        "EPUB_FIX_BATCH",
        "EPUB_FIX_DAILY_SCAN",
        "INGEST_DISCOVERY",
        "INGEST_BOOK",
        name="tasktype",
        native_enum=False,
    )

    # SQLite requires batch operations for column type changes
    if is_postgresql:
        op.alter_column(
            "task_statistics",
            "task_type",
            existing_type=sa.VARCHAR(length=18),
            type_=task_type_enum,
            existing_nullable=False,
        )
        op.alter_column(
            "tasks",
            "task_type",
            existing_type=sa.VARCHAR(length=18),
            type_=task_type_enum,
            existing_nullable=False,
        )
    else:
        # SQLite: Use batch operations to recreate table with new column type
        with op.batch_alter_table("task_statistics", schema=None) as batch_op:
            batch_op.alter_column(
                "task_type",
                existing_type=sa.VARCHAR(length=18),
                type_=task_type_enum,
                existing_nullable=False,
            )
        with op.batch_alter_table("tasks", schema=None) as batch_op:
            batch_op.alter_column(
                "task_type",
                existing_type=sa.VARCHAR(length=18),
                type_=task_type_enum,
                existing_nullable=False,
            )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # Detect database dialect
    connection = op.get_bind()
    is_postgresql = connection.dialect.name == "postgresql"

    # Note: We don't drop pg_trgm extension as it might be used by other tables
    # ### commands auto generated by Alembic - please adjust! ###

    # Define the enum type for task_type column (for downgrade)
    task_type_enum = sa.Enum(
        "BOOK_UPLOAD",
        "MULTI_BOOK_UPLOAD",
        "BOOK_CONVERT",
        "BOOK_STRIP_DRM",
        "EMAIL_SEND",
        "METADATA_BACKUP",
        "THUMBNAIL_GENERATE",
        "LIBRARY_SCAN",
        "AUTHOR_METADATA_FETCH",
        "OPENLIBRARY_DUMP_DOWNLOAD",
        "OPENLIBRARY_DUMP_INGEST",
        "EPUB_FIX_SINGLE",
        "EPUB_FIX_BATCH",
        "EPUB_FIX_DAILY_SCAN",
        name="tasktype",
        native_enum=False,
    )

    # SQLite requires batch operations for column type changes
    if is_postgresql:
        op.alter_column(
            "tasks",
            "task_type",
            existing_type=task_type_enum,
            type_=sa.VARCHAR(length=50),
            existing_nullable=False,
        )
        op.alter_column(
            "task_statistics",
            "task_type",
            existing_type=task_type_enum,
            type_=sa.VARCHAR(length=50),
            existing_nullable=False,
        )
    else:
        # SQLite: Use batch operations to recreate table with new column type
        with op.batch_alter_table("tasks", schema=None) as batch_op:
            batch_op.alter_column(
                "task_type",
                existing_type=task_type_enum,
                type_=sa.VARCHAR(length=50),
                existing_nullable=False,
            )
        with op.batch_alter_table("task_statistics", schema=None) as batch_op:
            batch_op.alter_column(
                "task_type",
                existing_type=task_type_enum,
                type_=sa.VARCHAR(length=50),
                existing_nullable=False,
            )
    op.create_index(
        op.f("ix_shelves_library_id_user_id_is_public"),
        "shelves",
        ["library_id", "user_id", "is_public"],
        unique=False,
    )
    op.create_index(
        op.f("ix_shelves_library_id_name_is_public"),
        "shelves",
        ["library_id", "name", "is_public"],
        unique=False,
    )
    op.drop_index(
        op.f("ix_library_scan_states_scan_status"), table_name="library_scan_states"
    )
    op.drop_index(
        op.f("ix_library_scan_states_library_id"), table_name="library_scan_states"
    )
    op.drop_index(
        op.f("ix_library_scan_states_last_scan_at"), table_name="library_scan_states"
    )
    op.drop_index(
        op.f("ix_library_scan_states_created_at"), table_name="library_scan_states"
    )
    op.drop_table("library_scan_states")
    # Drop GIN indexes created manually (PostgreSQL only)
    if is_postgresql:
        op.execute(sa.text("DROP INDEX IF EXISTS ix_openlibrary_works_subtitle"))
        op.execute(sa.text("DROP INDEX IF EXISTS ix_openlibrary_works_title"))
        op.execute(sa.text("DROP INDEX IF EXISTS ix_openlibrary_works_data"))
    op.drop_index("cuix_openlibrary_works_key", table_name="openlibrary_works")
    op.drop_table("openlibrary_works")
    # Drop GIN indexes created manually (PostgreSQL only)
    if is_postgresql:
        op.execute(sa.text("DROP INDEX IF EXISTS ix_openlibrary_editions_subtitle"))
        op.execute(sa.text("DROP INDEX IF EXISTS ix_openlibrary_editions_title"))
        op.execute(sa.text("DROP INDEX IF EXISTS ix_openlibrary_editions_data"))
    op.drop_index("ix_openlibrary_editions_workkey", table_name="openlibrary_editions")
    op.drop_index("cuix_openlibrary_editions_key", table_name="openlibrary_editions")
    op.drop_table("openlibrary_editions")
    op.drop_index(
        "ix_openlibrary_editionisbns_isbn", table_name="openlibrary_edition_isbns"
    )
    op.drop_index(
        "ix_openlibrary_editionisbns_editionkey", table_name="openlibrary_edition_isbns"
    )
    op.drop_index(
        "cuix_openlibrary_editionisbns_editionkey_isbn",
        table_name="openlibrary_edition_isbns",
    )
    op.drop_table("openlibrary_edition_isbns")
    # Drop GIN indexes created manually (PostgreSQL only)
    if is_postgresql:
        op.execute(sa.text("DROP INDEX IF EXISTS ix_openlibrary_authors_name"))
        op.execute(sa.text("DROP INDEX IF EXISTS ix_openlibrary_authors_data"))
    op.drop_index("cuix_openlibrary_authors_key", table_name="openlibrary_authors")
    op.drop_table("openlibrary_authors")
    op.drop_index(
        "ix_openlibrary_authorworks_workkey", table_name="openlibrary_author_works"
    )
    op.drop_index(
        "ix_openlibrary_authorworks_authorkey", table_name="openlibrary_author_works"
    )
    op.drop_index(
        "cuix_openlibrary_authorworks_authorkey_workkey",
        table_name="openlibrary_author_works",
    )
    op.drop_table("openlibrary_author_works")
    # ### end Alembic commands ###
