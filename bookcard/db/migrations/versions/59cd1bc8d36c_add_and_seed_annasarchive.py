# Copyright (C) 2025 knguyen and others
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.

"""Add and seed annasarchive.

Revision ID: 59cd1bc8d36c
Revises: d1b45e88976b
Create Date: 2026-01-14 19:28:13.919241

"""

import os
from collections.abc import Sequence
from datetime import UTC, datetime

import sqlalchemy as sa
from alembic import op

# revision identifiers, used by Alembic.
revision: str = "59cd1bc8d36c"
down_revision: str | Sequence[str] | None = "d1b45e88976b"
branch_labels: str | Sequence[str] | None = None
depends_on: str | Sequence[str] | None = None


def upgrade() -> None:
    """Upgrade schema."""
    # Detect database dialect
    connection = op.get_bind()
    is_postgresql = connection.dialect.name == "postgresql"

    # ### commands auto generated by Alembic - please adjust! ###

    indexer_type_enum = sa.Enum(
        "TORZNAB",
        "NEWZNAB",
        "TORRENT_RSS",
        "USENET_RSS",
        "CUSTOM",
        "ANNAS_ARCHIVE",
        name="indexertype",
        native_enum=False,
    )

    protocol_enum = sa.Enum(
        "TORRENT",
        "USENET",
        "HTTP",
        name="indexerprotocol",
        native_enum=False,
    )

    download_client_type_enum = sa.Enum(
        "QBITTORRENT",
        "TRANSMISSION",
        "DELUGE",
        "RTORRENT",
        "UTORRENT",
        "VUZE",
        "ARIA2",
        "FLOOD",
        "HADOUKEN",
        "FREEBOX_DOWNLOAD",
        "DOWNLOAD_STATION",
        "SABNZBD",
        "NZBGET",
        "NZBVORTEX",
        "PNEUMATIC",
        "TORRENT_BLACKHOLE",
        "USENET_BLACKHOLE",
        "DIRECT_HTTP",
        name="downloadclienttype",
        native_enum=False,
    )

    if is_postgresql:
        op.alter_column(
            "indexer_definitions",
            "indexer_type",
            existing_type=sa.VARCHAR(length=11),
            type_=indexer_type_enum,
            existing_nullable=False,
        )

        op.alter_column(
            "indexer_definitions",
            "protocol",
            existing_type=sa.VARCHAR(length=7),
            type_=protocol_enum,
            existing_nullable=False,
        )

        op.alter_column(
            "download_client_definitions",
            "client_type",
            existing_type=sa.VARCHAR(length=17),
            type_=download_client_type_enum,
            existing_nullable=False,
        )
    else:
        with op.batch_alter_table("indexer_definitions") as batch_op:
            batch_op.alter_column(
                "indexer_type",
                existing_type=sa.VARCHAR(length=11),
                type_=indexer_type_enum,
                existing_nullable=False,
            )

            batch_op.alter_column(
                "protocol",
                existing_type=sa.VARCHAR(length=7),
                type_=protocol_enum,
                existing_nullable=False,
            )

        with op.batch_alter_table("download_client_definitions") as batch_op:
            batch_op.alter_column(
                "client_type",
                existing_type=sa.VARCHAR(length=17),
                type_=download_client_type_enum,
                existing_nullable=False,
            )

    # Define table for data manipulation
    indexer_definitions = sa.table(
        "indexer_definitions",
        sa.column("name", sa.String),
        sa.column("indexer_type", sa.String),
        sa.column("protocol", sa.String),
        sa.column("base_url", sa.String),
        sa.column("api_key", sa.String),
        sa.column("enabled", sa.Boolean),
        sa.column("priority", sa.Integer),
        sa.column("timeout_seconds", sa.Integer),
        sa.column("retry_count", sa.Integer),
        sa.column("status", sa.String),
        sa.column("error_count", sa.Integer),
        sa.column("created_at", sa.DateTime),
        sa.column("updated_at", sa.DateTime),
    )

    download_client_definitions = sa.table(
        "download_client_definitions",
        sa.column("name", sa.String),
        sa.column("client_type", sa.String),
        sa.column("host", sa.String),
        sa.column("port", sa.Integer),
        sa.column("username", sa.String),
        sa.column("password", sa.String),
        sa.column("use_ssl", sa.Boolean),
        sa.column("enabled", sa.Boolean),
        sa.column("priority", sa.Integer),
        sa.column("timeout_seconds", sa.Integer),
        sa.column("category", sa.String),
        sa.column("download_path", sa.String),
        sa.column("additional_settings", sa.JSON),
        sa.column("status", sa.String),
        sa.column("error_count", sa.Integer),
        sa.column("created_at", sa.DateTime),
        sa.column("updated_at", sa.DateTime),
    )

    now = datetime.now(UTC)

    # Seed Anna's Archive
    connection = op.get_bind()
    indexer_name = "Anna's Archive"

    # Check if exists
    exists = connection.execute(
        sa.select(indexer_definitions.c.name).where(
            indexer_definitions.c.name == indexer_name
        )
    ).scalar()

    if not exists:
        op.bulk_insert(
            indexer_definitions,
            [
                {
                    "name": indexer_name,
                    "indexer_type": "ANNAS_ARCHIVE",
                    "protocol": "HTTP",
                    "base_url": "https://annas-archive.li",
                    "api_key": None,
                    "enabled": True,
                    "priority": 0,
                    "timeout_seconds": 30,
                    "retry_count": 3,
                    "status": "UNKNOWN",
                    "error_count": 0,
                    "created_at": now,
                    "updated_at": now,
                }
            ],
        )

    # Seed Direct HTTP Client
    client_name = "Direct HTTP"
    exists_client = connection.execute(
        sa.select(download_client_definitions.c.name).where(
            download_client_definitions.c.name == client_name
        )
    ).scalar()

    if not exists_client:
        ingest_dir = os.getenv("BOOKS_INGEST_DIR", "/data/books_ingest")
        op.bulk_insert(
            download_client_definitions,
            [
                {
                    "name": client_name,
                    "client_type": "DIRECT_HTTP",
                    "host": "localhost",
                    "port": 80,
                    "username": None,
                    "password": None,
                    "use_ssl": False,
                    "enabled": True,
                    "priority": 0,
                    "timeout_seconds": 30,
                    "category": None,
                    "download_path": ingest_dir,
                    "additional_settings": None,
                    "status": "UNHEALTHY",
                    "error_count": 0,
                    "created_at": now,
                    "updated_at": now,
                }
            ],
        )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # Detect database dialect
    connection = op.get_bind()
    is_postgresql = connection.dialect.name == "postgresql"

    # Define table for data manipulation
    indexer_definitions = sa.table(
        "indexer_definitions",
        sa.column("name", sa.String),
    )

    download_client_definitions = sa.table(
        "download_client_definitions",
        sa.column("name", sa.String),
    )

    # Remove seeded data
    op.execute(
        indexer_definitions.delete().where(
            indexer_definitions.c.name == "Anna's Archive"
        )
    )

    op.execute(
        download_client_definitions.delete().where(
            download_client_definitions.c.name == "Direct HTTP"
        )
    )

    # ### commands auto generated by Alembic - please adjust! ###

    indexer_type_enum = sa.Enum(
        "TORZNAB",
        "NEWZNAB",
        "TORRENT_RSS",
        "USENET_RSS",
        "CUSTOM",
        "ANNAS_ARCHIVE",
        name="indexertype",
        native_enum=False,
    )

    protocol_enum = sa.Enum(
        "TORRENT",
        "USENET",
        "HTTP",
        name="indexerprotocol",
        native_enum=False,
    )

    download_client_type_enum = sa.Enum(
        "QBITTORRENT",
        "TRANSMISSION",
        "DELUGE",
        "RTORRENT",
        "UTORRENT",
        "VUZE",
        "ARIA2",
        "FLOOD",
        "HADOUKEN",
        "FREEBOX_DOWNLOAD",
        "DOWNLOAD_STATION",
        "SABNZBD",
        "NZBGET",
        "NZBVORTEX",
        "PNEUMATIC",
        "TORRENT_BLACKHOLE",
        "USENET_BLACKHOLE",
        name="downloadclienttype",
        native_enum=False,
    )

    if is_postgresql:
        op.alter_column(
            "indexer_definitions",
            "protocol",
            existing_type=protocol_enum,
            type_=sa.VARCHAR(length=7),
            existing_nullable=False,
        )

        op.alter_column(
            "indexer_definitions",
            "indexer_type",
            existing_type=indexer_type_enum,
            type_=sa.VARCHAR(length=11),
            existing_nullable=False,
        )

        op.alter_column(
            "download_client_definitions",
            "client_type",
            existing_type=download_client_type_enum,
            type_=sa.VARCHAR(length=17),
            existing_nullable=False,
        )
    else:
        with op.batch_alter_table("indexer_definitions") as batch_op:
            batch_op.alter_column(
                "protocol",
                existing_type=protocol_enum,
                type_=sa.VARCHAR(length=7),
                existing_nullable=False,
            )

            batch_op.alter_column(
                "indexer_type",
                existing_type=indexer_type_enum,
                type_=sa.VARCHAR(length=11),
                existing_nullable=False,
            )

        with op.batch_alter_table("download_client_definitions") as batch_op:
            batch_op.alter_column(
                "client_type",
                existing_type=download_client_type_enum,
                type_=sa.VARCHAR(length=17),
                existing_nullable=False,
            )
    # ### end Alembic commands ###
